# CapÃ­tulo 05 â€” PrÃ©-Treinamento e GeraÃ§Ã£o de Texto

Nos capÃ­tulos anteriores, construÃ­mos o corpo de um modelo GPT.

- aprendemos como texto vira nÃºmeros  
- aprendemos como embeddings representam linguagem  
- aprendemos como self-attention constrÃ³i contexto  
- montamos um GPT funcional  

Agora surge a pergunta mais importante:

> Como o modelo aprende linguagem?

Este capÃ­tulo responde exatamente isso.

---

## O que significa treinar um modelo de linguagem

Um modelo GPT nÃ£o aprende gramÃ¡tica explicitamente.

Ele aprende padrÃµes estatÃ­sticos observando sequÃªncias de texto.

A tarefa fundamental de treinamento Ã©:

> prever o prÃ³ximo token com base nos tokens anteriores

Pode parecer simples, mas essa tarefa contÃ©m toda a complexidade da linguagem.

---

## O pipeline de treinamento de um LLM

Treinar um modelo envolve vÃ¡rias etapas que se repetem milhares ou milhÃµes de vezes.

![Pipeline de treinamento de um LLM](./infograficos/01-pipeline-treinamento.svg)

O fluxo geral Ã©:

1. Dataset de texto  
2. TokenizaÃ§Ã£o  
3. Forward pass no modelo  
4. CÃ¡lculo da loss  
5. Backpropagation  
6. AtualizaÃ§Ã£o dos pesos  

Esse ciclo Ã© conhecido como loop de treinamento.

---

## Como avaliamos se o modelo estÃ¡ aprendendo

Quando o modelo prevÃª o prÃ³ximo token, ele nÃ£o escolhe uma palavra diretamente.

Ele produz uma distribuiÃ§Ã£o de probabilidades para todas as palavras do vocabulÃ¡rio.

A qualidade do modelo depende de quÃ£o prÃ³ximas essas probabilidades estÃ£o do token correto.

---

## Cross Entropy: medindo o erro probabilÃ­stico

Para medir o erro do modelo usamos uma funÃ§Ã£o chamada **cross entropy**.

![Cross entropy explicada](./infograficos/02-cross-entropy.svg)

A cross entropy mede:

- quÃ£o diferente a distribuiÃ§Ã£o prevista estÃ¡ da distribuiÃ§Ã£o real
- quanto o modelo ficou "surpreso" com o token correto

Quanto menor a cross entropy, melhor o modelo.

---

## Perplexidade: interpretando a qualidade do modelo

Outra mÃ©trica importante Ã© a perplexidade.

Ela representa o grau de incerteza do modelo ao prever o prÃ³ximo token.

Uma perplexidade alta indica:

- modelo confuso
- muitas possibilidades plausÃ­veis

Uma perplexidade baixa indica:

- modelo confiante
- previsÃµes mais precisas

---

## O loop de treinamento completo

O aprendizado do modelo ocorre dentro de um ciclo repetitivo.

![Loop de treinamento completo](./infograficos/03-loop-treinamento.svg)

O ciclo consiste em:

### Forward Pass
O modelo recebe tokens e produz previsÃµes.

### CÃ¡lculo da Loss
A previsÃ£o Ã© comparada com o token real.

### Backpropagation
O erro Ã© propagado pela rede para calcular gradientes.

### AtualizaÃ§Ã£o de Pesos
Os pesos sÃ£o ajustados para reduzir o erro.

Esse processo Ã© repetido em batches e epochs.

---

## Treinamento em batches

Treinar usando todo o dataset de uma vez seria computacionalmente inviÃ¡vel.

Por isso, dividimos os dados em pequenos grupos chamados batches.

Isso permite:

- melhor eficiÃªncia computacional
- estabilidade do treinamento
- paralelizaÃ§Ã£o

---

## Monitorando o aprendizado do modelo

Durante o treinamento, monitoramos:

- training loss
- validation loss

Se a loss de validaÃ§Ã£o comeÃ§a a aumentar enquanto a loss de treinamento diminui, pode indicar overfitting.

---

## Depois do treinamento: geraÃ§Ã£o de texto

Depois que o modelo aprende padrÃµes da linguagem, ele pode gerar texto.

Mas geraÃ§Ã£o nÃ£o Ã© determinÃ­stica.

O modelo produz probabilidades e precisamos decidir como escolher o prÃ³ximo token.

---

## EstratÃ©gias de geraÃ§Ã£o de texto

Existem vÃ¡rias formas de gerar texto a partir das probabilidades.

![EstratÃ©gias de decoding](./infograficos/04-decoding-strategies.svg)

### Greedy Decoding
Sempre escolhe o token mais provÃ¡vel.

- Texto previsÃ­vel
- Pouca criatividade

### Temperature Sampling
Controla aleatoriedade das probabilidades.

- Temperatura baixa â†’ mais previsÃ­vel  
- Temperatura alta â†’ mais criativo  

### Top-k Sampling
Escolhe entre os k tokens mais provÃ¡veis.

- Controla diversidade
- Evita escolhas improvÃ¡veis

### Nucleus Sampling (Top-p)
Escolhe tokens que compÃµem uma probabilidade acumulada.

- EstratÃ©gia usada em muitos LLMs modernos
- Equilibra coerÃªncia e diversidade

---

## Salvando modelos: checkpoints

Treinar modelos grandes pode levar horas, dias ou semanas.

Por isso salvamos estados intermediÃ¡rios do modelo chamados checkpoints.

![Checkpoints de treinamento](./infograficos/05-checkpoints.svg)

Checkpoints permitem:

- retomar treinamento
- evitar perda de progresso
- compartilhar modelos
- reproduzir experimentos

---

## Pesos prÃ©-treinados e modelos fundacionais

Modelos modernos raramente sÃ£o treinados do zero para cada tarefa.

Eles sÃ£o:

1. PrÃ©-treinados em grandes datasets  
2. Adaptados para tarefas especÃ­ficas  

Esse conceito Ã© conhecido como foundation models.

---

## LimitaÃ§Ãµes do treinamento didÃ¡tico

Neste projeto usamos:

- datasets pequenos  
- modelos compactos  
- treinamento curto  

Essas simplificaÃ§Ãµes permitem execuÃ§Ã£o no Colab, mas mantÃªm os princÃ­pios fundamentais do treinamento de LLMs.

---

## O que construiremos no notebook

Neste capÃ­tulo vamos implementar:

- cÃ¡lculo da cross entropy loss
- loop de treinamento completo
- monitoramento do treinamento
- diferentes estratÃ©gias de geraÃ§Ã£o
- salvamento e carregamento de modelos
- comparaÃ§Ã£o entre modelos antes e depois do treinamento

---

## Preparando os prÃ³ximos capÃ­tulos

Depois de aprender como treinar um modelo, surge o prÃ³ximo passo natural:

> Como adaptar um modelo para tarefas especÃ­ficas?

Nos prÃ³ximos capÃ­tulos exploraremos:

- fine-tuning  
- instruction tuning  
- alinhamento de modelos  

---

## ðŸ§¾ GlossÃ¡rio RÃ¡pido â€” CapÃ­tulo 05

**Cross Entropy**  
MÃ©trica que mede diferenÃ§a entre distribuiÃ§Ãµes de probabilidade.

**Perplexidade**  
Medida de incerteza do modelo ao prever tokens.

**Forward Pass**  
Etapa onde o modelo produz previsÃµes.

**Backpropagation**  
Processo de ajuste dos pesos com base no erro.

**Batch**  
Grupo de exemplos usados em uma etapa do treinamento.

**Epoch**  
Uma passagem completa pelo dataset.

**Sampling**  
Processo de escolha do prÃ³ximo token com base em probabilidades.

**Checkpoint**  
Salvamento do estado do modelo durante o treinamento.

---

> Nos capÃ­tulos anteriores construÃ­mos o cÃ©rebro do modelo.  
> Neste capÃ­tulo comeÃ§amos a ensinar o modelo a pensar.

---

### ðŸš€ Execute agora

- **Notebook:** `05-pre-treinamento/notebook.ipynb`
- **Abrir direto no Colab:** [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vongrossi/fazendo-um-llm-do-zero/blob/main/05-pre-treinamento/notebook.ipynb)
