{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Cap√≠tulo 03 ‚Äî Self-Attention do Zero\n",
        "\n",
        "Neste notebook vamos implementar, passo a passo, o mecanismo que tornou os Transformers e os LLMs modernos poss√≠veis: **Self-Attention**.\n",
        "\n",
        "Aqui vamos aprender:\n",
        "\n",
        "- Como calcular pesos de aten√ß√£o\n",
        "- Como criar vetores de contexto\n",
        "- Como surgem Query, Key e Value\n",
        "- Como funciona m√°scara causal\n",
        "- Como funciona Multi-Head Attention (conceitual)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "V_RVmjt9BvER"
      },
      "id": "V_RVmjt9BvER"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(42)\n"
      ],
      "metadata": {
        "id": "w9nxeBw9B5lb"
      },
      "id": "w9nxeBw9B5lb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 ‚Äî Representando tokens como vetores\n",
        "\n",
        "Vamos come√ßar com embeddings simples.\n",
        "\n",
        "Cada token da frase ser√° representado como um vetor.\n"
      ],
      "metadata": {
        "id": "7Cac7fOXCAYE"
      },
      "id": "7Cac7fOXCAYE"
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = [\"Your\", \"journey\", \"starts\", \"with\", \"one\", \"step\"]\n",
        "\n",
        "embedding_dim = 3\n",
        "\n",
        "embeddings = torch.rand(len(tokens), embedding_dim)\n",
        "\n",
        "embeddings\n"
      ],
      "metadata": {
        "id": "rOeXWd2kCCsE"
      },
      "id": "rOeXWd2kCCsE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 - Aten√ß√£o Intuitiva\n",
        "\n",
        "Aten√ß√£o pode ser entendida como uma m√©dia ponderada dos vetores de entrada.\n",
        "\n",
        "Vamos calcular o contexto do segundo token (\"journey\").\n"
      ],
      "metadata": {
        "id": "FQvXou12CRKt"
      },
      "id": "FQvXou12CRKt"
    },
    {
      "cell_type": "code",
      "source": [
        "query = embeddings[1]\n",
        "\n",
        "attention_scores = torch.matmul(embeddings, query)\n",
        "\n",
        "attention_scores\n"
      ],
      "metadata": {
        "id": "a4ch10VOCUTr"
      },
      "id": "a4ch10VOCUTr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora normalizamos os pesos usando softmax.\n"
      ],
      "metadata": {
        "id": "ULI7gRdXCZOr"
      },
      "id": "ULI7gRdXCZOr"
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights = F.softmax(attention_scores, dim=0)\n",
        "\n",
        "attention_weights\n"
      ],
      "metadata": {
        "id": "slc5_rQXCbXl"
      },
      "id": "slc5_rQXCbXl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora criamos o vetor de contexto.\n"
      ],
      "metadata": {
        "id": "VrPqIkfRCdc1"
      },
      "id": "VrPqIkfRCdc1"
    },
    {
      "cell_type": "code",
      "source": [
        "context_vector = torch.sum(attention_weights.unsqueeze(1) * embeddings, dim=0)\n",
        "\n",
        "context_vector\n"
      ],
      "metadata": {
        "id": "_MYrt463Cene"
      },
      "id": "_MYrt463Cene",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 - Self-Attention completo\n",
        "\n",
        "Agora cada token calcula seu pr√≥prio contexto."
      ],
      "metadata": {
        "id": "Hnu0wV22Cg7X"
      },
      "id": "Hnu0wV22Cg7X"
    },
    {
      "cell_type": "code",
      "source": [
        "def self_attention(inputs):\n",
        "\n",
        "    scores = torch.matmul(inputs, inputs.T)\n",
        "    weights = F.softmax(scores, dim=1)\n",
        "    context = torch.matmul(weights, inputs)\n",
        "\n",
        "    return context, weights\n",
        "\n",
        "context_vectors, attention_matrix = self_attention(embeddings)\n",
        "\n",
        "attention_matrix\n"
      ],
      "metadata": {
        "id": "Uib7ndH0CpQs"
      },
      "id": "Uib7ndH0CpQs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4 - Query, Key e Value\n",
        "\n",
        "Transformers n√£o usam embeddings diretamente.\n",
        "\n",
        "Eles criam tr√™s proje√ß√µes trein√°veis:\n",
        "\n",
        "- Query\n",
        "- Key\n",
        "- Value\n"
      ],
      "metadata": {
        "id": "45gRtRWXCtY1"
      },
      "id": "45gRtRWXCtY1"
    },
    {
      "cell_type": "code",
      "source": [
        "d_model = embeddings.shape[1]\n",
        "d_k = 4\n",
        "\n",
        "W_q = torch.rand(d_model, d_k)\n",
        "W_k = torch.rand(d_model, d_k)\n",
        "W_v = torch.rand(d_model, d_k)\n",
        "\n",
        "Q = embeddings @ W_q\n",
        "K = embeddings @ W_k\n",
        "V = embeddings @ W_v\n",
        "\n",
        "Q\n"
      ],
      "metadata": {
        "id": "-_7KLiFSCx8w"
      },
      "id": "-_7KLiFSCx8w",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5 - Self-Attention com QKV"
      ],
      "metadata": {
        "id": "Ty8jU7GRCzG8"
      },
      "id": "Ty8jU7GRCzG8"
    },
    {
      "cell_type": "code",
      "source": [
        "scores = Q @ K.T\n",
        "scores = scores / torch.sqrt(torch.tensor(d_k, dtype=torch.float32))\n",
        "\n",
        "weights = F.softmax(scores, dim=1)\n",
        "\n",
        "context = weights @ V\n",
        "\n",
        "context\n"
      ],
      "metadata": {
        "id": "IfISnQuyC35n"
      },
      "id": "IfISnQuyC35n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6 - M√°scara Causal\n",
        "\n",
        "Modelos GPT n√£o podem acessar tokens futuros."
      ],
      "metadata": {
        "id": "z6uSAJcIC51I"
      },
      "id": "z6uSAJcIC51I"
    },
    {
      "cell_type": "code",
      "source": [
        "def causal_mask(size):\n",
        "    return torch.triu(torch.ones(size, size), diagonal=1)\n",
        "\n",
        "mask = causal_mask(len(tokens))\n",
        "mask\n"
      ],
      "metadata": {
        "id": "BnFGuv-hC-DI"
      },
      "id": "BnFGuv-hC-DI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "masked_scores = scores.masked_fill(mask == 1, float(\"-inf\"))\n",
        "\n",
        "masked_weights = F.softmax(masked_scores, dim=1)\n",
        "\n",
        "masked_weights\n"
      ],
      "metadata": {
        "id": "oIhcFO3nDDjp"
      },
      "id": "oIhcFO3nDDjp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7 - ## Dropout na Aten√ß√£o\n",
        "\n",
        "Dropout ajuda a evitar overfitting."
      ],
      "metadata": {
        "id": "fsIGvtqEDEjR"
      },
      "id": "fsIGvtqEDEjR"
    },
    {
      "cell_type": "code",
      "source": [
        "dropout = torch.nn.Dropout(p=0.3)\n",
        "\n",
        "dropped_weights = dropout(masked_weights)\n",
        "\n",
        "dropped_weights\n"
      ],
      "metadata": {
        "id": "glxFHISZDIly"
      },
      "id": "glxFHISZDIly",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8 - Multi-Head Attention\n",
        "\n",
        "Agora dividimos Q, K e V em m√∫ltiplas cabe√ßas."
      ],
      "metadata": {
        "id": "hHdYQyuBDTBE"
      },
      "id": "hHdYQyuBDTBE"
    },
    {
      "cell_type": "code",
      "source": [
        "def split_heads(x, num_heads):\n",
        "    batch, dim = x.shape\n",
        "    head_dim = dim // num_heads\n",
        "    return x.view(batch, num_heads, head_dim)\n",
        "\n",
        "num_heads = 2\n",
        "\n",
        "Q_heads = split_heads(Q, num_heads)\n",
        "K_heads = split_heads(K, num_heads)\n",
        "V_heads = split_heads(V, num_heads)\n",
        "\n",
        "Q_heads.shape\n"
      ],
      "metadata": {
        "id": "zEEvQyswDVDB"
      },
      "id": "zEEvQyswDVDB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora aplicamos aten√ß√£o em cada cabe√ßa.\n"
      ],
      "metadata": {
        "id": "qRArWcpfDXT3"
      },
      "id": "qRArWcpfDXT3"
    },
    {
      "cell_type": "code",
      "source": [
        "heads_output = []\n",
        "\n",
        "for i in range(num_heads):\n",
        "\n",
        "    scores = Q_heads[:, i] @ K_heads[:, i].T\n",
        "    weights = F.softmax(scores, dim=1)\n",
        "    context = weights @ V_heads[:, i]\n",
        "\n",
        "    heads_output.append(context)\n",
        "\n",
        "multi_head_output = torch.cat(heads_output, dim=1)\n",
        "\n",
        "multi_head_output\n"
      ],
      "metadata": {
        "id": "EKn7fnGEDZWx"
      },
      "id": "EKn7fnGEDZWx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9 ‚Äî Conectando com Transformers\n",
        "\n",
        "### Onde isso entra no Transformer?\n",
        "\n",
        "Self-Attention √© o primeiro grande bloco da arquitetura GPT.\n",
        "\n",
        "Ele permite que cada token compreenda o contexto global antes das camadas feed-forward.\n"
      ],
      "metadata": {
        "id": "AF1ECeYcDjUw"
      },
      "id": "AF1ECeYcDjUw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10 - Conclus√£o\n",
        "\n",
        "Voc√™ acabou de implementar o cora√ß√£o dos Transformers.\n",
        "\n",
        "Voc√™ aprendeu:\n",
        "\n",
        "‚úî Weighted attention  \n",
        "‚úî Self-attention  \n",
        "‚úî QKV projections  \n",
        "‚úî Causal masking  \n",
        "‚úî Dropout  \n",
        "‚úî Multi-head attention  \n",
        "\n",
        "No pr√≥ximo cap√≠tulo vamos usar esse conhecimento para construir um GPT completo.\n"
      ],
      "metadata": {
        "id": "J07OqMbHDsno"
      },
      "id": "J07OqMbHDsno"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üé∞ Bonus Stage"
      ],
      "metadata": {
        "id": "cWwTleACDz7G"
      },
      "id": "cWwTleACDz7G"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(attention_matrix.detach(), cmap=\"viridis\")\n",
        "plt.colorbar()\n",
        "plt.title(\"Attention Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "SyfDtsh7D3UX"
      },
      "id": "SyfDtsh7D3UX",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}