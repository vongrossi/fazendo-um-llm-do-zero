# CapÃ­tulo 03 â€” AtenÃ§Ã£o (Self-Attention)

Nos capÃ­tulos anteriores, aprendemos:

- o que Ã© um LLM
- como texto vira nÃºmeros
- como vetores representam linguagem

Agora chegamos ao ponto onde os LLMs realmente comeÃ§am a â€œpensarâ€.

A pergunta central deste capÃ­tulo Ã©:

> Como o modelo decide quais partes do contexto sÃ£o importantes?

Essa pergunta levou Ã  criaÃ§Ã£o do mecanismo mais revolucionÃ¡rio da histÃ³ria dos modelos de linguagem:

**Self-Attention**

---
---

## Arquivos do CapÃ­tulo
- [README.md](README.md)
- [notebook.ipynb](notebook.ipynb)
- [links.md](links.md)
- [infograficos/README.md](infograficos/README.md)


## O problema do contexto

Vamos comeÃ§ar com um exemplo clÃ¡ssico.

Traduza a frase alemÃ£:

> Kannst du mir helfen diesen Satz zu Ã¼bersetzen?

Se tentarmos traduzir palavra por palavra, obtemos algo incorreto.
A traduÃ§Ã£o correta depende de entender a frase inteira.

![Contexto importa na traduÃ§Ã£o](./infograficos/01-contexto-importa.png)

Isso acontece porque linguagem nÃ£o Ã© linear.
Palavras dependem de outras que podem aparecer:

- antes
- depois
- muito distantes na frase

Modelos antigos tinham dificuldade com isso.

---

## A ideia intuitiva da atenÃ§Ã£o

AtenÃ§Ã£o nasce de uma ideia simples:

> Cada palavra deve decidir quanto ela precisa olhar para outras palavras.

Por exemplo, na frase:

> "O gato que estava no telhado miou"

A palavra â€œmiouâ€ precisa entender quem realizou a aÃ§Ã£o.
Para isso, ela precisa prestar mais atenÃ§Ã£o em â€œgatoâ€ do que em â€œtelhadoâ€.

![IntuiÃ§Ã£o da atenÃ§Ã£o](./infograficos/02-self-attention-intuicao.png)

AtenÃ§Ã£o permite que cada token atribua **pesos de importÃ¢ncia** aos outros tokens.

---

## Construindo vetores de contexto

Matematicamente, atenÃ§Ã£o constrÃ³i um novo vetor chamado **vetor de contexto**.

Esse vetor Ã© calculado como uma mÃ©dia ponderada dos vetores de entrada.

![Weighted context vector](./infograficos/03-weighted-context.png)

Cada token recebe:

- pesos de atenÃ§Ã£o
- combinaÃ§Ã£o ponderada dos vetores de entrada

Esse vetor final representa o token considerando todo o contexto relevante.

---

## Introduzindo Query, Key e Value

AtÃ© agora, falamos apenas de pesos.
Mas como esses pesos sÃ£o calculados?

Aqui entram trÃªs projeÃ§Ãµes fundamentais:

- Query (Q)
- Key (K)
- Value (V)

Cada token gera trÃªs representaÃ§Ãµes diferentes:

- Query â†’ o que estou procurando?
- Key â†’ o que eu ofereÃ§o?
- Value â†’ qual informaÃ§Ã£o eu carrego?

![ProjeÃ§Ãµes Q, K e V](./infograficos/04-qkv-projecoes.png)

Os pesos de atenÃ§Ã£o sÃ£o calculados comparando:

## Query Ã— Key


Depois, usamos esses pesos para combinar os Values.

---

## Self-Attention com pesos treinÃ¡veis

Nos Transformers reais, Q, K e V nÃ£o sÃ£o cÃ³pias dos embeddings.

Eles sÃ£o criados por matrizes treinÃ¡veis:

- Wq
- Wk
- Wv

Essas matrizes permitem que o modelo aprenda diferentes formas de representar o contexto.

![Self-attention treinÃ¡vel](./infograficos/05-self-attention-treinavel.svg)

Isso transforma atenÃ§Ã£o em um mecanismo adaptÃ¡vel.

---

## MÃ¡scara causal: impedindo o modelo de ver o futuro

Modelos autoregressivos como GPT precisam obedecer uma regra fundamental:

> O modelo nÃ£o pode ver tokens futuros durante o treinamento.

Para garantir isso, usamos uma **mÃ¡scara causal**.

![MÃ¡scara causal](./infograficos/06-causal-mask.svg)

Essa mÃ¡scara:

- bloqueia conexÃµes com tokens futuros
- forÃ§a o modelo a prever o prÃ³ximo token honestamente
- garante consistÃªncia entre treino e geraÃ§Ã£o

---

## Dropout na atenÃ§Ã£o

Durante o treinamento, tambÃ©m aplicamos **dropout** nos pesos de atenÃ§Ã£o.

![Dropout aplicado Ã  atenÃ§Ã£o](./infograficos/07-dropout-attention.svg)

Dropout:

- remove conexÃµes aleatÃ³rias temporariamente
- evita overfitting
- melhora generalizaÃ§Ã£o

---

## Multi-Head Attention

AtÃ© agora, usamos apenas uma forma de atenÃ§Ã£o.

Mas linguagem Ã© complexa.
Um Ãºnico mecanismo pode nÃ£o capturar todas as relaÃ§Ãµes.

Multi-head attention resolve isso permitindo que o modelo:

- observe mÃºltiplos padrÃµes simultaneamente
- capture relaÃ§Ãµes sintÃ¡ticas e semÃ¢nticas paralelamente

Cada cabeÃ§a aprende um tipo diferente de relacionamento linguÃ­stico.

![Multi-head attention](./infograficos/08-multi-head.svg)

Os resultados das cabeÃ§as sÃ£o combinados em um Ãºnico vetor de contexto.

---

## Onde a atenÃ§Ã£o entra no Transformer

Agora podemos posicionar a atenÃ§Ã£o dentro da arquitetura completa.

![Self-attention dentro do Transformer](./infograficos/09-self-attention-no-transformer.svg)

Self-attention Ã© o primeiro grande bloco do Transformer.
Ele permite que o modelo:

- compreenda contexto global
- construa representaÃ§Ãµes ricas
- prepare dados para camadas posteriores

---

## Por que atenÃ§Ã£o mudou tudo

Antes dos Transformers:

- modelos processavam texto sequencialmente
- dependÃªncias longas eram difÃ­ceis
- treinamento era lento

Com atenÃ§Ã£o:

- contexto global Ã© acessÃ­vel
- processamento pode ser paralelo
- modelos escalam melhor

Essa mudanÃ§a permitiu a criaÃ§Ã£o dos LLMs modernos.

---

## Conectando com o prÃ³ximo capÃ­tulo

Agora sabemos:

- como tokens viram vetores
- como vetores viram contexto
- como atenÃ§Ã£o decide relevÃ¢ncia

No prÃ³ximo capÃ­tulo, vamos juntar essas peÃ§as e construir:

> A arquitetura completa de um GPT

---

## ðŸ§¾ GlossÃ¡rio RÃ¡pido â€” CapÃ­tulo 03

**Self-Attention**  
Mecanismo que permite a um token analisar outros tokens da mesma sequÃªncia.

**Query (Q)**  
Representa o que um token busca no contexto.

**Key (K)**  
Representa o que cada token oferece como informaÃ§Ã£o.

**Value (V)**  
ConteÃºdo real usado para construir o vetor de contexto.

**MÃ¡scara Causal**  
Bloqueia acesso a tokens futuros.

**Multi-Head Attention**  
Executa mÃºltiplos mecanismos de atenÃ§Ã£o em paralelo.

---

### ðŸš€ Execute agora

- **Notebook:** `03-atencao/notebook.ipynb`
- **Abrir direto no Colab:** [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vongrossi/fazendo-um-llm-do-zero/blob/main/03-atencao/notebook.ipynb)
