# CapÃ­tulo 07 â€” Instruction Tuning

Nos capÃ­tulos anteriores, construÃ­mos progressivamente um modelo de linguagem completo.

NÃ³s ensinamos o modelo a:

- transformar texto em nÃºmeros  
- construir representaÃ§Ãµes semÃ¢nticas  
- aprender relaÃ§Ãµes contextuais com atenÃ§Ã£o  
- gerar linguagem coerente  
- adaptar comportamento para tarefas supervisionadas  

Agora surge a pergunta final desta jornada:

> Como ensinar o modelo a responder instruÃ§Ãµes humanas?

Este capÃ­tulo responde essa pergunta.

---

## Do Modelo Base ao Assistente Conversacional

Durante o prÃ©-treinamento, um modelo aprende padrÃµes da linguagem observando grandes volumes de texto.

Ele aprende:

- como frases sÃ£o construÃ­das  
- como ideias sÃ£o conectadas  
- como palavras costumam aparecer juntas  

Mas esse aprendizado Ã© passivo.

O modelo aprende **como a linguagem continua**, nÃ£o **como responder perguntas ou executar tarefas**.

---

## O Surgimento do Instruction Tuning

Instruction tuning Ã© o processo de ensinar o modelo a responder instruÃ§Ãµes humanas.

Ele transforma o modelo de:

ðŸ‘‰ um gerador de texto  
ðŸ‘‰ em um assistente capaz de interagir com pessoas  

---

## Uma Analogia Humana

Podemos comparar o treinamento de LLMs com a formaÃ§Ã£o de um profissional.

PrÃ©-treinamento Ã© equivalente Ã  educaÃ§Ã£o geral.

Fine-tuning supervisionado Ã© equivalente a uma especializaÃ§Ã£o tÃ©cnica.

Instruction tuning Ã© equivalente a aprender a trabalhar com clientes e interpretar pedidos humanos.

![Modelo Base vs Modelo Alinhado](./infograficos/01-instruction-tuning-visao-geral.svg)

---

## Como Modelos Aprendem a Seguir InstruÃ§Ãµes

Modelos nÃ£o entendem linguagem da forma como humanos entendem.

Eles aprendem observando exemplos.

Se queremos que o modelo responda instruÃ§Ãµes, precisamos fornecer exemplos de:

- instruÃ§Ãµes humanas  
- contexto adicional (quando necessÃ¡rio)  
- respostas desejadas  

---

## Estrutura de Dados para Instruction Tuning

Datasets de instruction tuning geralmente seguem um formato estruturado.

Eles podem conter trÃªs componentes:

1. Instruction  
2. Input (opcional)  
3. Response  

![Formato de Dados para InstruÃ§Ãµes](./infograficos/02-formato-dados-instrucao.svg)

Esse formato permite que o modelo aprenda padrÃµes de interaÃ§Ã£o.

---

## A ImportÃ¢ncia da InstruÃ§Ã£o Estruturada

Durante o treinamento, o modelo nÃ£o recebe apenas perguntas.

Ele recebe instruÃ§Ãµes estruturadas que indicam claramente:

- qual Ã© a tarefa  
- qual Ã© o contexto  
- qual resposta Ã© esperada  

Essa estrutura ensina o modelo a interpretar intenÃ§Ãµes humanas.

---

## Mascaramento da Loss

Instruction tuning utiliza uma estratÃ©gia fundamental:

O modelo aprende apenas com a resposta.

![Mascaramento da Loss](./infograficos/03-mascaramento-loss-resposta.svg)

Durante o treinamento:

- tokens da instruÃ§Ã£o sÃ£o usados como contexto  
- tokens da resposta sÃ£o usados para cÃ¡lculo da loss  

Isso impede que o modelo aprenda a reproduzir a instruÃ§Ã£o e o incentiva a aprender a responder.

---

## Pipeline de Supervised Fine-Tuning (SFT)

Instruction tuning Ã© implementado como uma forma especializada de fine-tuning supervisionado.

![Pipeline SFT](./infograficos/04-pipeline-sft.svg)

O pipeline envolve:

1. Dataset de instruÃ§Ãµes  
2. TokenizaÃ§Ã£o estruturada  
3. ReutilizaÃ§Ã£o de pesos prÃ©-treinados  
4. Treinamento supervisionado  
5. AvaliaÃ§Ã£o das respostas  

---

## Avaliando Modelos Conversacionais

Modelos conversacionais sÃ£o difÃ­ceis de avaliar com mÃ©tricas tradicionais.

Accuracy e F1-score nÃ£o capturam:

- coerÃªncia semÃ¢ntica  
- utilidade da resposta  
- naturalidade do texto  
- aderÃªncia Ã  instruÃ§Ã£o  

![AvaliaÃ§Ã£o de Respostas](./infograficos/05-avaliacao-respostas.svg)

Por isso, avaliaÃ§Ã£o qualitativa se torna essencial.

---

## O Papel da Qualidade do Dataset

Instruction tuning depende fortemente da qualidade dos exemplos fornecidos.

Datasets com respostas claras e bem estruturadas produzem modelos mais confiÃ¡veis.

Datasets inconsistentes podem gerar comportamento imprevisÃ­vel.

---

## LimitaÃ§Ãµes do Instruction Tuning DidÃ¡tico

Neste projeto utilizamos:

- datasets pequenos  
- modelos compactos  
- treinamento simplificado  

Essas simplificaÃ§Ãµes permitem execuÃ§Ã£o no Colab e facilitam aprendizado conceitual.

Sistemas reais utilizam:

- milhÃµes de exemplos  
- mÃºltiplas etapas de alinhamento  
- avaliaÃ§Ã£o humana contÃ­nua  

---

## O Que Construiremos no Notebook

Neste capÃ­tulo vamos implementar:

- dataset educacional de instruÃ§Ãµes  
- formataÃ§Ã£o de instruÃ§Ãµes estruturadas  
- mascaramento da loss  
- treinamento supervisionado orientado a respostas  
- comparaÃ§Ã£o entre modelo base e modelo instruction-tuned  
- avaliaÃ§Ã£o qualitativa de respostas  

---

## Conectando Toda a Jornada da SÃ©rie

Ao longo desta sÃ©rie vocÃª aprendeu como:

- linguagem Ã© representada numericamente  
- atenÃ§Ã£o permite compreensÃ£o contextual  
- modelos GPT sÃ£o construÃ­dos  
- modelos aprendem linguagem  
- modelos sÃ£o adaptados para tarefas especÃ­ficas  
- modelos aprendem a seguir instruÃ§Ãµes humanas  

Este Ã© o fluxo fundamental que sustenta os assistentes baseados em LLMs modernos.

---

## Para Onde a Jornada Continua

Instruction tuning Ã© apenas uma etapa do alinhamento de modelos.

Sistemas modernos tambÃ©m utilizam:

- reinforcement learning com feedback humano (RLHF)  
- avaliaÃ§Ã£o automatizada de qualidade  
- ajuste contÃ­nuo com dados reais  

Esses temas representam a fronteira atual da pesquisa em LLMs.

---

## ðŸ§¾ GlossÃ¡rio RÃ¡pido â€” CapÃ­tulo 07

**Instruction Tuning**  
Processo de treinar modelos para seguir instruÃ§Ãµes humanas.

**Supervised Fine-Tuning (SFT)**  
Treinamento supervisionado usando pares instruÃ§Ã£o-resposta.

**InstruÃ§Ã£o Estruturada**  
Formato padronizado usado para orientar o modelo.

**Masking da Loss**  
TÃ©cnica que calcula erro apenas sobre tokens da resposta.

**Alignment**  
Processo de adaptar comportamento do modelo para expectativas humanas.

---

> No inÃ­cio da sÃ©rie, ensinamos o modelo a reconhecer padrÃµes da linguagem.  
> No final da sÃ©rie, ensinamos o modelo a conversar.

---

### ðŸš€ Execute agora

- **Notebook:** `07-instruction-tuning/notebook.ipynb`
- **Abrir direto no Colab:** [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vongrossi/fazendo-um-llm-do-zero/blob/main/07-instruction-tuning/notebook.ipynb)
