
# Cap√≠tulo 07 ‚Äî Instruction Tuning

Nos cap√≠tulos anteriores, constru√≠mos progressivamente um modelo de linguagem completo:

- Cap√≠tulo 01 ‚Äî O que √© um LLM  
- Cap√≠tulo 02 ‚Äî Como texto vira n√∫meros  
- Cap√≠tulo 03 ‚Äî Como o modelo constr√≥i contexto com aten√ß√£o  
- Cap√≠tulo 04 ‚Äî Construindo um GPT do zero  
- Cap√≠tulo 05 ‚Äî Como modelos aprendem linguagem  
- Cap√≠tulo 06 ‚Äî Fine-Tuning para Classifica√ß√£o  

Neste cap√≠tulo final exploramos um dos avan√ßos mais importantes da evolu√ß√£o dos LLMs:

> Ensinar modelos a seguir instru√ß√µes humanas.

---

## üéØ Objetivo do Cap√≠tulo

Ao final deste cap√≠tulo, voc√™ dever√° ser capaz de:

- entender o conceito de instruction tuning
- compreender como modelos conversacionais s√£o treinados
- preparar datasets de instru√ß√µes e respostas
- aplicar supervised fine-tuning para gera√ß√£o orientada
- entender mascaramento de loss em tarefas conversacionais
- avaliar respostas geradas por modelos
- compreender como surgem assistentes baseados em LLMs

Este cap√≠tulo representa a transi√ß√£o entre **modelos que aprendem linguagem** e **modelos que interagem com pessoas**.

---

## üß≠ Como este cap√≠tulo est√° organizado

O conte√∫do segue uma progress√£o conceitual at√© a implementa√ß√£o pr√°tica.

---

### 1. O que √© Instruction Tuning

Nesta se√ß√£o exploramos como modelos passam de prever texto para responder instru√ß√µes.

Ser√£o discutidos:

- modelos base vs modelos alinhados
- supervised fine-tuning
- papel do comportamento conversacional
- evolu√ß√£o hist√≥rica dos LLMs

---

### 2. Estrutura de Dados para Instru√ß√µes

Aqui estudamos como preparar datasets que ensinam o modelo a responder perguntas e executar tarefas.

Ser√£o abordados:

- estrutura instruction / input / response
- formata√ß√£o de prompts estruturados
- padroniza√ß√£o de dados conversacionais
- impacto da qualidade do dataset

---

### 3. Mascaramento da Loss

Instruction tuning utiliza uma estrat√©gia importante:

O modelo aprende apenas com a parte da resposta.

Nesta se√ß√£o exploramos:

- como separar prompt e resposta
- por que mascarar tokens do prompt
- como isso influencia o comportamento do modelo
- impacto no aprendizado supervisionado

---

### 4. Pipeline de Supervised Fine-Tuning (SFT)

Nesta se√ß√£o implementamos o pipeline completo de instruction tuning:

- prepara√ß√£o do dataset de instru√ß√µes
- tokeniza√ß√£o estruturada
- treinamento supervisionado para gera√ß√£o
- reutiliza√ß√£o de pesos pr√©-treinados
- monitoramento do treinamento

---

### 5. Avalia√ß√£o de Modelos Instruction-Tuned

Modelos conversacionais n√£o s√£o avaliados apenas por m√©tricas num√©ricas.

Ser√£o exploradas formas de avalia√ß√£o:

- compara√ß√£o qualitativa de respostas
- an√°lise de coer√™ncia e relev√¢ncia
- valida√ß√£o manual de outputs
- limita√ß√µes das m√©tricas tradicionais

---

### 6. Uso Pr√°tico e Aplica√ß√µes

Depois do treinamento, exploramos como utilizar o modelo para:

- responder perguntas abertas
- executar tarefas simples
- interagir com prompts estruturados
- simular comportamento conversacional

---

## üß™ Parte pr√°tica (notebook)

Este cap√≠tulo inclui um notebook execut√°vel no Google Colab que implementa:

- cria√ß√£o de dataset de instru√ß√µes
- formata√ß√£o de prompts estruturados
- adapta√ß√£o do GPTMini para gera√ß√£o supervisionada
- treinamento supervisionado para respostas orientadas
- avalia√ß√£o qualitativa de respostas
- compara√ß√£o entre modelo base e modelo instruction-tuned

O notebook mant√©m foco did√°tico e explica√ß√µes passo a passo.

---

## üìä Infogr√°ficos

Este cap√≠tulo utiliza infogr√°ficos para explicar:

- evolu√ß√£o de modelos base para modelos alinhados
- estrutura de datasets de instru√ß√µes
- mascaramento de loss
- pipeline de supervised fine-tuning
- avalia√ß√£o de respostas conversacionais

Os detalhes dos infogr√°ficos est√£o documentados em:
- `infograficos/README.md`

---

## ‚ñ∂Ô∏è Como executar

1. Leia o di√°rio do cap√≠tulo:
- `diario.md`

2. Execute o notebook:
- `notebook.ipynb`

3. Ou abra diretamente no Google Colab:
- veja `links.md`

---

## üé• Material complementar

Este cap√≠tulo √© inspirado nas explica√ß√µes e implementa√ß√µes do pr√≥prio autor do livro, que demonstra como modelos GPT podem ser adaptados para seguir instru√ß√µes humanas.

O material complementar apresenta:

- constru√ß√£o de datasets conversacionais
- treinamento supervisionado orientado a respostas
- avalia√ß√£o de comportamento de modelos

---

## üìò Refer√™ncia

Este cap√≠tulo √© inspirado no Cap√≠tulo 7 do livro:

**Build a Large Language Model (From Scratch)**  
Sebastian Raschka

O conte√∫do foi adaptado para:

- abordagem did√°tica em portugu√™s
- execu√ß√£o pr√°tica no Google Colab
- foco em compreens√£o conceitual do instruction tuning
- amplia√ß√£o pedag√≥gica dos conceitos apresentados no livro

---

## ‚ö†Ô∏è Observa√ß√£o importante

Instruction tuning √© uma etapa fundamental na constru√ß√£o de assistentes baseados em LLMs.

Neste projeto utilizamos:

- datasets pequenos e educacionais
- modelos compactos
- treinamento simplificado

Essas simplifica√ß√µes permitem execu√ß√£o em ambientes educacionais, mantendo os princ√≠pios utilizados em sistemas reais.

---

## üß† Por que este cap√≠tulo √© o encerramento da s√©rie

Neste ponto o leitor compreende:

- como modelos aprendem linguagem
- como modelos s√£o adaptados para tarefas espec√≠ficas
- como modelos aprendem a seguir instru√ß√µes humanas
- como surgem assistentes baseados em LLMs
- como pipelines modernos de treinamento s√£o estruturados

Este cap√≠tulo conecta todos os conceitos fundamentais necess√°rios para compreender o funcionamento dos grandes modelos de linguagem modernos.
