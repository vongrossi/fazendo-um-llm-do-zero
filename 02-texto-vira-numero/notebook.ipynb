{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Setup do repositÃ³rio\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "\n",
        "REPO_URL = \"https://github.com/vongrossi/fazendo-um-llm-do-zero.git\"\n",
        "REPO_DIR = \"fazendo-um-llm-do-zero\"\n",
        "\n",
        "if not os.path.exists(REPO_DIR):\n",
        "    !git clone {REPO_URL}\n",
        "\n",
        "os.chdir(REPO_DIR)\n",
        "\n",
        "print(\"DiretÃ³rio atual:\", os.getcwd())\n"
      ],
      "metadata": {
        "id": "6iGct1ovFQiY"
      },
      "id": "6iGct1ovFQiY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CapÃ­tulo 02 â€” Texto vira nÃºmero\n",
        "\n",
        "Neste notebook vamos explorar:\n",
        "\n",
        "ðŸŽ¯ Como texto vira nÃºmeros  \n",
        "ðŸŽ¯ Como construir um vocabulÃ¡rio  \n",
        "ðŸŽ¯ Como tokenizaÃ§Ã£o funciona  \n",
        "ðŸŽ¯ Como criar pares input-target  \n",
        "ðŸŽ¯ Como preparar dados para um GPT-like  \n",
        "\n",
        "Este notebook Ã© o ponto onde a teoria comeÃ§a a virar pipeline real.\n"
      ],
      "metadata": {
        "id": "2Pejom2pFTpd"
      },
      "id": "2Pejom2pFTpd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalando dependencias"
      ],
      "metadata": {
        "id": "cyrXn-RqFbpI"
      },
      "id": "cyrXn-RqFbpI"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install -r 02-texto-vira-numero/requirements.txt\n"
      ],
      "metadata": {
        "id": "u9f76p5wFY--"
      },
      "id": "u9f76p5wFY--",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports e seed"
      ],
      "metadata": {
        "id": "wbs_EFjnFibq"
      },
      "id": "wbs_EFjnFibq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import Counter\n",
        "\n",
        "sys.path.append(\"02-texto-vira-numero\")\n",
        "\n",
        "from colab_setup import seed_everything\n",
        "\n",
        "seed_everything(42)\n"
      ],
      "metadata": {
        "id": "SyKj9ji7Fj68"
      },
      "id": "SyKj9ji7Fj68"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parte 1 â€” Texto nÃ£o Ã© nÃºmero"
      ],
      "metadata": {
        "id": "KqLrBJXHFs_2"
      },
      "id": "KqLrBJXHFs_2"
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "LLMs aprendem padrÃµes de linguagem.\n",
        "LLMs precisam transformar texto em nÃºmeros.\n",
        "Modelos sÃ³ conseguem operar sobre vetores.\n",
        "\"\"\"\n",
        "\n",
        "print(text)\n"
      ],
      "metadata": {
        "id": "5_GUoe7jFlxi"
      },
      "id": "5_GUoe7jFlxi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parte 2 â€” TokenizaÃ§Ã£o simples"
      ],
      "metadata": {
        "id": "1WRnUffLF1IC"
      },
      "id": "1WRnUffLF1IC"
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_tokenize(text):\n",
        "    return text.lower().split()\n",
        "\n",
        "tokens = simple_tokenize(text)\n",
        "\n",
        "print(tokens)\n"
      ],
      "metadata": {
        "id": "TeiQURc8F30U"
      },
      "id": "TeiQURc8F30U",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parte 3 â€” Construindo vocabulÃ¡rio"
      ],
      "metadata": {
        "id": "YzmRcvdtF7Tk"
      },
      "id": "YzmRcvdtF7Tk"
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = sorted(set(tokens))\n",
        "\n",
        "token_to_id = {token: idx for idx, token in enumerate(vocab)}\n",
        "id_to_token = {idx: token for token, idx in token_to_id.items()}\n",
        "\n",
        "print(\"VocabulÃ¡rio:\", vocab)\n"
      ],
      "metadata": {
        "id": "-upMPfB3F8io"
      },
      "id": "-upMPfB3F8io",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encode"
      ],
      "metadata": {
        "id": "b2WQFwJ7GAVe"
      },
      "id": "b2WQFwJ7GAVe"
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(text):\n",
        "    return [token_to_id[token] for token in simple_tokenize(text)]\n",
        "\n",
        "encoded = encode(text)\n",
        "print(encoded)\n"
      ],
      "metadata": {
        "id": "TqBGf2tcGBVe"
      },
      "id": "TqBGf2tcGBVe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decode"
      ],
      "metadata": {
        "id": "BBQoN0IBGDlY"
      },
      "id": "BBQoN0IBGDlY"
    },
    {
      "cell_type": "code",
      "source": [
        "def decode(ids):\n",
        "    return \" \".join([id_to_token[i] for i in ids])\n",
        "\n",
        "print(decode(encoded))\n"
      ],
      "metadata": {
        "id": "zIKpZblHGGM2"
      },
      "id": "zIKpZblHGGM2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parte 4 â€” Introduzindo Embeddings"
      ],
      "metadata": {
        "id": "Aa0BsMp0GJn-"
      },
      "id": "Aa0BsMp0GJn-"
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando embeddings simples\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "embedding_dim = 4\n",
        "\n",
        "embeddings = np.random.randn(vocab_size, embedding_dim)\n",
        "\n",
        "print(\"Shape embeddings:\", embeddings.shape)"
      ],
      "metadata": {
        "id": "VrJQzCYJGSqd"
      },
      "id": "VrJQzCYJGSqd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtendo embedding de tokens\n",
        "\n",
        "token_ids = encode(\"llms aprendem padrÃµes\")\n",
        "\n",
        "token_embeddings = embeddings[token_ids]\n",
        "\n",
        "print(token_embeddings)"
      ],
      "metadata": {
        "id": "WogQ1iwfGjZT"
      },
      "id": "WogQ1iwfGjZT",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parte 5 â€” Sliding Window (ESSENCIAL)"
      ],
      "metadata": {
        "id": "naEAMgasGs_g"
      },
      "id": "naEAMgasGs_g"
    },
    {
      "cell_type": "code",
      "source": [
        "# FunÃ§Ã£o sliding window\n",
        "\n",
        "def create_input_target_pairs(token_ids, context_size):\n",
        "\n",
        "    inputs = []\n",
        "    targets = []\n",
        "\n",
        "    for i in range(len(token_ids) - context_size):\n",
        "        input_seq = token_ids[i:i+context_size]\n",
        "        target = token_ids[i+context_size]\n",
        "\n",
        "        inputs.append(input_seq)\n",
        "        targets.append(target)\n",
        "\n",
        "    return np.array(inputs), np.array(targets)\n"
      ],
      "metadata": {
        "id": "QmI9ehFXGkbx"
      },
      "id": "QmI9ehFXGkbx",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gerando pares"
      ],
      "metadata": {
        "id": "qZ-_0YCfG42o"
      },
      "id": "qZ-_0YCfG42o"
    },
    {
      "cell_type": "code",
      "source": [
        "context_size = 3\n",
        "\n",
        "inputs, targets = create_input_target_pairs(encoded, context_size)\n",
        "\n",
        "print(\"Inputs:\")\n",
        "print(inputs)\n",
        "\n",
        "print(\"\\nTargets:\")\n",
        "print(targets)\n"
      ],
      "metadata": {
        "id": "mqjGujHnG6O3"
      },
      "id": "mqjGujHnG6O3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parte 6 â€” Visualizando pares"
      ],
      "metadata": {
        "id": "YScFFzY3G-7I"
      },
      "id": "YScFFzY3G-7I"
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrando pares de forma interpretÃ¡vel\n",
        "for inp, tgt in zip(inputs, targets):\n",
        "\n",
        "    print(\"INPUT :\", decode(inp))\n",
        "    print(\"TARGET:\", id_to_token[tgt])\n",
        "    print(\"---\")"
      ],
      "metadata": {
        "id": "uYBKRgN-HAeL"
      },
      "id": "uYBKRgN-HAeL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parte 7 â€” Preparando entrada GPT-like"
      ],
      "metadata": {
        "id": "NafMgDH6HJvm"
      },
      "id": "NafMgDH6HJvm"
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertendo inputs para embeddings\n",
        "input_embeddings = embeddings[inputs]\n",
        "\n",
        "print(input_embeddings.shape)"
      ],
      "metadata": {
        "id": "MnhzTxIcHLME"
      },
      "id": "MnhzTxIcHLME",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parte 8 â€” IntuiÃ§Ã£o de positional embeddings"
      ],
      "metadata": {
        "id": "jyJbBhxpHVlX"
      },
      "id": "jyJbBhxpHVlX"
    },
    {
      "cell_type": "code",
      "source": [
        "# SimulaÃ§Ã£o simples\n",
        "positional_embeddings = np.random.randn(context_size, embedding_dim)\n",
        "\n",
        "final_embeddings = input_embeddings + positional_embeddings\n",
        "\n",
        "print(final_embeddings.shape)"
      ],
      "metadata": {
        "id": "iw4cJIZKHXLN"
      },
      "id": "iw4cJIZKHXLN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parte 9 â€” ConclusÃ£o\n",
        "### O que acabamos de construir?\n",
        "\n",
        "Criamos o pipeline bÃ¡sico que alimenta um GPT:\n",
        "\n",
        "Texto â†’ Tokens â†’ IDs â†’ Embeddings â†’ SequÃªncia contextual\n",
        "\n",
        "Nos prÃ³ximos capÃ­tulos vamos:\n",
        "- aprender como atenÃ§Ã£o usa esses vetores\n",
        "- construir blocos Transformer\n",
        "- finalmente montar um GPT do zero\n",
        "\n",
        "Este notebook representa a fundaÃ§Ã£o matemÃ¡tica da linguagem em LLMs.\n"
      ],
      "metadata": {
        "id": "jFZUkJKmHdvj"
      },
      "id": "jFZUkJKmHdvj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extras (ExperimentaÃ§Ã£o)\n",
        "\n",
        "1. Mude o context_size e observe os pares gerados.\n",
        "2. Aumente embedding_dim e veja o impacto na matriz.\n",
        "3. Teste outro dataset.\n"
      ],
      "metadata": {
        "id": "vN8JL8uYHosV"
      },
      "id": "vN8JL8uYHosV"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}