{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6iGct1ovFQiY",
      "metadata": {
        "id": "6iGct1ovFQiY"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# Setup do reposit√≥rio\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "\n",
        "REPO_URL = \"https://github.com/vongrossi/fazendo-um-llm-do-zero.git\"\n",
        "REPO_DIR = \"fazendo-um-llm-do-zero\"\n",
        "\n",
        "if not os.path.exists(REPO_DIR):\n",
        "    !git clone {REPO_URL}\n",
        "\n",
        "os.chdir(REPO_DIR)\n",
        "\n",
        "print(\"Diret√≥rio atual:\", os.getcwd())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2Pejom2pFTpd",
      "metadata": {
        "id": "2Pejom2pFTpd"
      },
      "source": [
        "# Cap√≠tulo 02 ‚Äî Texto vira n√∫mero\n",
        "\n",
        "Este notebook acompanha o Cap√≠tulo 02 da s√©rie **Fazendo um LLM do Zero**.\n",
        "\n",
        "üéØ **Objetivos deste notebook:**\n",
        "- Entender como texto vira n√∫meros\n",
        "- Construir um vocabul√°rio a partir do zero\n",
        "- Compreender o funcionamento da tokeniza√ß√£o\n",
        "- Criar pares input-target (janela deslizante)\n",
        "- Preparar dados reais para um modelo GPT-like\n",
        "\n",
        "Este notebook √© o ponto onde a teoria come√ßa a virar pipeline real.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cyrXn-RqFbpI",
      "metadata": {
        "id": "cyrXn-RqFbpI"
      },
      "source": [
        "## 1. Setup e Configura√ß√£o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "u9f76p5wFY--",
      "metadata": {
        "id": "u9f76p5wFY--"
      },
      "outputs": [],
      "source": [
        "!pip -q install -r 02-texto-vira-numero/requirements.txt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wbs_EFjnFibq",
      "metadata": {
        "id": "wbs_EFjnFibq"
      },
      "source": [
        "### 1.1 Imports e Seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SyKj9ji7Fj68",
      "metadata": {
        "id": "SyKj9ji7Fj68"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import Counter\n",
        "\n",
        "sys.path.append(\"02-texto-vira-numero\")\n",
        "\n",
        "from colab_setup import seed_everything\n",
        "\n",
        "seed_everything(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KqLrBJXHFs_2",
      "metadata": {
        "id": "KqLrBJXHFs_2"
      },
      "source": [
        "## 2. Texto n√£o √© n√∫mero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5_GUoe7jFlxi",
      "metadata": {
        "id": "5_GUoe7jFlxi"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"\n",
        "LLMs aprendem padr√µes de linguagem.\n",
        "LLMs precisam transformar texto em n√∫meros.\n",
        "Modelos s√≥ conseguem operar sobre vetores.\n",
        "\"\"\"\n",
        "\n",
        "print(text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1WRnUffLF1IC",
      "metadata": {
        "id": "1WRnUffLF1IC"
      },
      "source": [
        "## 3. Tokeniza√ß√£o Simples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TeiQURc8F30U",
      "metadata": {
        "id": "TeiQURc8F30U"
      },
      "outputs": [],
      "source": [
        "def simple_tokenize(text):\n",
        "    return text.lower().split()\n",
        "\n",
        "tokens = simple_tokenize(text)\n",
        "\n",
        "print(tokens)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YzmRcvdtF7Tk",
      "metadata": {
        "id": "YzmRcvdtF7Tk"
      },
      "source": [
        "## 4. Construindo Vocabul√°rio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-upMPfB3F8io",
      "metadata": {
        "id": "-upMPfB3F8io"
      },
      "outputs": [],
      "source": [
        "vocab = sorted(set(tokens))\n",
        "\n",
        "token_to_id = {token: idx for idx, token in enumerate(vocab)}\n",
        "id_to_token = {idx: token for token, idx in token_to_id.items()}\n",
        "\n",
        "print(\"Vocabul√°rio:\", vocab)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2WQFwJ7GAVe",
      "metadata": {
        "id": "b2WQFwJ7GAVe"
      },
      "source": [
        "### 4.1 Encode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TqBGf2tcGBVe",
      "metadata": {
        "id": "TqBGf2tcGBVe"
      },
      "outputs": [],
      "source": [
        "def encode(text):\n",
        "    return [token_to_id[token] for token in simple_tokenize(text)]\n",
        "\n",
        "encoded = encode(text)\n",
        "print(encoded)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BBQoN0IBGDlY",
      "metadata": {
        "id": "BBQoN0IBGDlY"
      },
      "source": [
        "### 4.2 Decode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zIKpZblHGGM2",
      "metadata": {
        "id": "zIKpZblHGGM2"
      },
      "outputs": [],
      "source": [
        "def decode(ids):\n",
        "    return \" \".join([id_to_token[i] for i in ids])\n",
        "\n",
        "print(decode(encoded))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Aa0BsMp0GJn-",
      "metadata": {
        "id": "Aa0BsMp0GJn-"
      },
      "source": [
        "## 5. Introduzindo Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VrJQzCYJGSqd",
      "metadata": {
        "id": "VrJQzCYJGSqd"
      },
      "outputs": [],
      "source": [
        "# Criando embeddings simples\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "embedding_dim = 4\n",
        "\n",
        "embeddings = np.random.randn(vocab_size, embedding_dim)\n",
        "\n",
        "print(\"Shape embeddings:\", embeddings.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "WogQ1iwfGjZT",
      "metadata": {
        "id": "WogQ1iwfGjZT"
      },
      "outputs": [],
      "source": [
        "# Obtendo embedding de tokens\n",
        "\n",
        "token_ids = encode(\"llms aprendem padr√µes\")\n",
        "\n",
        "token_embeddings = embeddings[token_ids]\n",
        "\n",
        "print(token_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "naEAMgasGs_g",
      "metadata": {
        "id": "naEAMgasGs_g"
      },
      "source": [
        "## 6. Sliding Window (ESSENCIAL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "QmI9ehFXGkbx",
      "metadata": {
        "id": "QmI9ehFXGkbx"
      },
      "outputs": [],
      "source": [
        "# Fun√ß√£o sliding window\n",
        "\n",
        "def create_input_target_pairs(token_ids, context_size):\n",
        "\n",
        "    inputs = []\n",
        "    targets = []\n",
        "\n",
        "    for i in range(len(token_ids) - context_size):\n",
        "        input_seq = token_ids[i:i+context_size]\n",
        "        target = token_ids[i+context_size]\n",
        "\n",
        "        inputs.append(input_seq)\n",
        "        targets.append(target)\n",
        "\n",
        "    return np.array(inputs), np.array(targets)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qZ-_0YCfG42o",
      "metadata": {
        "id": "qZ-_0YCfG42o"
      },
      "source": [
        "### 6.1 Gerando pares input-target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mqjGujHnG6O3",
      "metadata": {
        "id": "mqjGujHnG6O3"
      },
      "outputs": [],
      "source": [
        "context_size = 3\n",
        "\n",
        "inputs, targets = create_input_target_pairs(encoded, context_size)\n",
        "\n",
        "print(\"Inputs:\")\n",
        "print(inputs)\n",
        "\n",
        "print(\"\\nTargets:\")\n",
        "print(targets)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YScFFzY3G-7I",
      "metadata": {
        "id": "YScFFzY3G-7I"
      },
      "source": [
        "## 7. Visualizando Pares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uYBKRgN-HAeL",
      "metadata": {
        "id": "uYBKRgN-HAeL"
      },
      "outputs": [],
      "source": [
        "# Mostrando pares de forma interpret√°vel\n",
        "for inp, tgt in zip(inputs, targets):\n",
        "\n",
        "    print(\"INPUT :\", decode(inp))\n",
        "    print(\"TARGET:\", id_to_token[tgt])\n",
        "    print(\"---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NafMgDH6HJvm",
      "metadata": {
        "id": "NafMgDH6HJvm"
      },
      "source": [
        "## 8. Preparando Entrada GPT-like"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MnhzTxIcHLME",
      "metadata": {
        "id": "MnhzTxIcHLME"
      },
      "outputs": [],
      "source": [
        "# Convertendo inputs para embeddings\n",
        "input_embeddings = embeddings[inputs]\n",
        "\n",
        "print(input_embeddings.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jyJbBhxpHVlX",
      "metadata": {
        "id": "jyJbBhxpHVlX"
      },
      "source": [
        "## 9. Intui√ß√£o de Positional Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iw4cJIZKHXLN",
      "metadata": {
        "id": "iw4cJIZKHXLN"
      },
      "outputs": [],
      "source": [
        "# Simula√ß√£o simples\n",
        "positional_embeddings = np.random.randn(context_size, embedding_dim)\n",
        "\n",
        "final_embeddings = input_embeddings + positional_embeddings\n",
        "\n",
        "print(final_embeddings.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jFZUkJKmHdvj",
      "metadata": {
        "id": "jFZUkJKmHdvj"
      },
      "source": [
        "## 10. Conclus√£o\n",
        "\n",
        "### 10.1 O que acabamos de construir?\n",
        "\n",
        "Criamos o pipeline b√°sico que alimenta um GPT:\n",
        "\n",
        "Texto ‚Üí Tokens ‚Üí IDs ‚Üí Embeddings ‚Üí Sequ√™ncia contextual\n",
        "\n",
        "Nos pr√≥ximos cap√≠tulos vamos:\n",
        "- aprender como aten√ß√£o usa esses vetores\n",
        "- construir blocos Transformer\n",
        "- finalmente montar um GPT do zero\n",
        "\n",
        "Este notebook representa a funda√ß√£o matem√°tica da linguagem em LLMs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vN8JL8uYHosV",
      "metadata": {
        "id": "vN8JL8uYHosV"
      },
      "source": [
        "## 11. Extras (Experimenta√ß√£o)\n",
        "\n",
        "1. Mude o context_size e observe os pares gerados.\n",
        "2. Aumente embedding_dim e veja o impacto na matriz.\n",
        "3. Teste outro dataset.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
