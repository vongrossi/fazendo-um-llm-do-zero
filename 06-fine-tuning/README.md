# Cap√≠tulo 06 ‚Äî Fine-Tuning para Classifica√ß√£o

Nos cap√≠tulos anteriores, constru√≠mos e treinamos um modelo GPT did√°tico:

- Cap√≠tulo 01 ‚Äî O que √© um LLM  
- Cap√≠tulo 02 ‚Äî Como texto vira n√∫meros  
- Cap√≠tulo 03 ‚Äî Como o modelo constr√≥i contexto com aten√ß√£o  
- Cap√≠tulo 04 ‚Äî Construindo um GPT do zero  
- Cap√≠tulo 05 ‚Äî Como modelos aprendem linguagem  

Agora chegamos a uma das aplica√ß√µes mais importantes dos LLMs:

> Adaptar modelos pr√©-treinados para resolver tarefas espec√≠ficas.

Neste cap√≠tulo exploramos como transformar um modelo GPT em um classificador supervisionado.

---

## üéØ Objetivo do Cap√≠tulo

Ao final deste cap√≠tulo, voc√™ dever√° ser capaz de:

- entender o conceito de fine-tuning
- compreender a diferen√ßa entre pr√©-treinamento e adapta√ß√£o supervisionada
- transformar um modelo generativo em um modelo de classifica√ß√£o
- implementar uma camada de classifica√ß√£o sobre um GPT
- treinar o modelo com dados rotulados
- compreender estrat√©gias de congelamento e ajuste de pesos
- avaliar desempenho com m√©tricas de classifica√ß√£o
- usar o modelo treinado para prever classes de novos textos

Este cap√≠tulo marca a transi√ß√£o entre **modelos de linguagem gerais** e **modelos especializados em tarefas reais**.

---

## üß≠ Como este cap√≠tulo est√° organizado

O conte√∫do segue uma progress√£o do entendimento conceitual at√© a implementa√ß√£o pr√°tica.

---

### 1. Pr√©-Treinamento vs Fine-Tuning

Nesta se√ß√£o exploramos a diferen√ßa entre:

- modelos pr√©-treinados
- adapta√ß√£o supervisionada para tarefas espec√≠ficas

Ser√£o discutidos:

- foundation models
- transfer√™ncia de conhecimento
- especializa√ß√£o de modelos

---

### 2. Transformando GPT em um Classificador

Aqui estudamos como reutilizar o conhecimento lingu√≠stico do modelo para classifica√ß√£o.

Ser√£o abordados:

- extra√ß√£o de representa√ß√µes contextuais
- pooling de embeddings
- adi√ß√£o de uma camada de classifica√ß√£o (classification head)
- adapta√ß√£o do objetivo de treinamento

---

### 3. Estrat√©gias de Fine-Tuning

Nesta se√ß√£o exploramos diferentes abordagens para adaptar modelos:

- fine-tuning completo
- congelamento de camadas
- ajuste parcial do modelo
- impacto do tamanho do dataset
- trade-offs entre custo computacional e generaliza√ß√£o

---

### 4. Treinamento Supervisionado

Implementamos o pipeline completo de treinamento para classifica√ß√£o:

- prepara√ß√£o de dataset rotulado
- tokeniza√ß√£o de dados supervisionados
- treinamento com cross entropy para classes
- valida√ß√£o do modelo
- monitoramento de m√©tricas

---

### 5. Avalia√ß√£o de Modelos de Classifica√ß√£o

Ser√£o exploradas m√©tricas fundamentais:

- accuracy
- precision
- recall
- F1-score
- confusion matrix

Esta se√ß√£o demonstra como avaliar modelos al√©m da simples taxa de acerto.

---

### 6. Infer√™ncia e Uso Pr√°tico

Depois do treinamento, exploramos como utilizar o modelo para:

- classificar novos textos
- interpretar previs√µes
- analisar erros do modelo
- validar comportamento em cen√°rios reais

---

## üß™ Parte pr√°tica (notebook)

Este cap√≠tulo inclui um notebook execut√°vel no Google Colab que implementa:

- cria√ß√£o de um modelo GPT adaptado para classifica√ß√£o
- reutiliza√ß√£o de pesos pr√©-treinados
- treinamento supervisionado com dataset rotulado
- compara√ß√£o entre estrat√©gias de fine-tuning
- avalia√ß√£o com m√©tricas de classifica√ß√£o
- infer√™ncia com novos textos

O notebook prioriza clareza conceitual e explica√ß√µes passo a passo.

---

## üìä Infogr√°ficos

Este cap√≠tulo utiliza infogr√°ficos para explicar:

- rela√ß√£o entre pr√©-treinamento e fine-tuning
- estrutura de um classification head
- estrat√©gias de congelamento de camadas
- pipeline de treinamento supervisionado
- interpreta√ß√£o de m√©tricas de classifica√ß√£o

Os detalhes dos infogr√°ficos est√£o documentados em:

- [infograficos/README.md](infograficos/README.md)

---

## ‚ñ∂Ô∏è Como executar

1. Leia o di√°rio do cap√≠tulo:
   - [diario.md](diario.md)

2. Execute o notebook:
   - [notebook.ipynb](notebook.ipynb)

3. Ou abra diretamente no Google Colab:
   - [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vongrossi/fazendo-um-llm-do-zero/blob/main/06-fine-tuning/notebook.ipynb)
   - ou veja mais detalhes em [links.md](links.md)


---

## üé• Material complementar

Este cap√≠tulo √© inspirado nas explica√ß√µes e implementa√ß√µes do pr√≥prio autor do livro, que demonstra como modelos GPT podem ser adaptados para tarefas supervisionadas, como classifica√ß√£o de texto.

O material complementar apresenta:

- adapta√ß√£o de modelos generativos
- exemplos pr√°ticos de classifica√ß√£o com LLMs
- demonstra√ß√£o de fine-tuning supervisionado

---

## üìò Refer√™ncia

Este cap√≠tulo √© inspirado no Cap√≠tulo 6 do livro:

**Build a Large Language Model (From Scratch)**  
Sebastian Raschka

O conte√∫do foi adaptado para:

- abordagem did√°tica em portugu√™s
- execu√ß√£o pr√°tica no Google Colab
- foco em compreens√£o conceitual do fine-tuning
- amplia√ß√£o pedag√≥gica dos conceitos apresentados no livro

---

## ‚ö†Ô∏è Observa√ß√£o importante

Fine-tuning √© uma das t√©cnicas mais utilizadas para adaptar LLMs para aplica√ß√µes reais.

Neste projeto utilizamos:

- datasets pequenos
- modelos compactos
- treinamento simplificado

Essas simplifica√ß√µes permitem execu√ß√£o em ambientes educacionais, mantendo os princ√≠pios utilizados em sistemas de produ√ß√£o.

---

## üß† Por que este cap√≠tulo √© fundamental

Neste √© o momento onde fica compreensivel:

- como adaptar modelos para tarefas espec√≠ficas
- como reutilizar conhecimento pr√©-treinado
- como preparar modelos para aplica√ß√µes reais
- como avaliar qualidade em tarefas supervisionadas
- como evoluir para t√©cnicas avan√ßadas como instruction tuning e alinhamento de modelos

Ap√≥s este cap√≠tulo, estaremos preparado para explorar aplica√ß√µes pr√°ticas e especializa√ß√£o de LLMs.



