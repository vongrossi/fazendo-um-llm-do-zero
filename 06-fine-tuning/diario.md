# CapÃ­tulo 06 â€” Fine-Tuning para ClassificaÃ§Ã£o

Nos capÃ­tulos anteriores, aprendemos como construir e treinar um modelo GPT capaz de aprender padrÃµes da linguagem.

- transformamos texto em nÃºmeros  
- construÃ­mos mecanismos de atenÃ§Ã£o  
- montamos um modelo GPT completo  
- ensinamos o modelo a aprender linguagem  

Agora surge uma nova pergunta:

> Como usamos esse conhecimento para resolver problemas reais?

Este capÃ­tulo responde exatamente isso.

---
---

## Arquivos do CapÃ­tulo
- [README.md](README.md)
- [notebook.ipynb](notebook.ipynb)
- [links.md](links.md)
- [infograficos/README.md](infograficos/README.md)


## O que Ã© Fine-Tuning

Um modelo de linguagem aprende padrÃµes gerais da linguagem durante o prÃ©-treinamento.

Ele aprende:

- gramÃ¡tica
- semÃ¢ntica
- relaÃ§Ãµes entre palavras
- estrutura de frases

Mas ele nÃ£o nasce sabendo executar tarefas especÃ­ficas.

Fine-tuning Ã© o processo de adaptar um modelo prÃ©-treinado para resolver uma tarefa supervisionada.

---

## PrÃ©-Treinamento vs EspecializaÃ§Ã£o

Podemos imaginar o treinamento de um LLM como o aprendizado humano.

O prÃ©-treinamento Ã© equivalente Ã  educaÃ§Ã£o bÃ¡sica e geral.

Fine-tuning Ã© equivalente Ã  especializaÃ§Ã£o profissional.

![PrÃ©-treinamento vs Fine-tuning](./infograficos/01-pretrain-vs-finetune.png)

Durante o prÃ©-treinamento o modelo aprende linguagem em geral.  
Durante o fine-tuning o modelo aprende a executar tarefas especÃ­ficas.

---

## Transformando um modelo generativo em classificador

Modelos GPT sÃ£o projetados para prever o prÃ³ximo token.

Para transformar o modelo em classificador precisamos modificar o objetivo do treinamento.

Em vez de prever a prÃ³xima palavra, o modelo passa a prever uma classe associada ao texto.

---

## Extraindo representaÃ§Ãµes do modelo

Quando um texto passa pelo GPT, cada token gera uma representaÃ§Ã£o contextual.

Essas representaÃ§Ãµes contÃªm o entendimento do modelo sobre o texto.

Para classificaÃ§Ã£o precisamos transformar essas representaÃ§Ãµes em uma decisÃ£o final.

---

## Classification Head

A soluÃ§Ã£o mais comum Ã© adicionar uma camada de classificaÃ§Ã£o no topo do modelo.

![Classification Head](./infograficos/02-classification-head.png)

Essa camada recebe a representaÃ§Ã£o do texto e produz logits para cada classe.

Esse processo reutiliza o conhecimento linguÃ­stico jÃ¡ aprendido pelo modelo.

---

## Como escolher a representaÃ§Ã£o do texto

Existem diferentes estratÃ©gias para extrair uma representaÃ§Ã£o global:

- usar o embedding do Ãºltimo token
- usar mÃ©dia dos embeddings da sequÃªncia
- usar tokens especiais

Neste capÃ­tulo utilizaremos uma abordagem simples e didÃ¡tica baseada na Ãºltima posiÃ§Ã£o da sequÃªncia.

---

## EstratÃ©gias de Fine-Tuning

Nem sempre precisamos treinar todo o modelo novamente.

Existem diferentes estratÃ©gias:

### Fine-Tuning Completo

Todos os pesos do modelo sÃ£o atualizados.

Vantagens:
- maior capacidade de adaptaÃ§Ã£o

Desvantagens:
- maior custo computacional
- maior risco de overfitting

---

### Congelamento de Camadas

Podemos congelar parte do modelo e treinar apenas algumas camadas.

![Freeze vs Unfreeze](./infograficos/03-freeze-vs-unfreeze.png)

EstratÃ©gias comuns incluem:

- treinar apenas a camada de classificaÃ§Ã£o
- treinar apenas as Ãºltimas camadas
- liberar gradualmente o treinamento do modelo

Essa abordagem reduz custo computacional e melhora estabilidade.

---

## Treinamento Supervisionado

Fine-tuning utiliza datasets rotulados.

Cada exemplo contÃ©m:

- texto de entrada
- rÃ³tulo associado

O treinamento passa a minimizar o erro entre a classe prevista e a classe real.

---

## Pipeline de treinamento para classificaÃ§Ã£o

O fluxo geral do fine-tuning Ã© semelhante ao treinamento do modelo de linguagem, mas com objetivo diferente.

![Pipeline de treinamento supervisionado](./infograficos/04-treino-classificacao-pipeline.svg)

O pipeline inclui:

1. Texto rotulado  
2. TokenizaÃ§Ã£o  
3. Processamento pelo GPT  
4. ExtraÃ§Ã£o de representaÃ§Ã£o do texto  
5. Camada de classificaÃ§Ã£o  
6. CÃ¡lculo da loss supervisionada  
7. AtualizaÃ§Ã£o dos pesos  

---

## Avaliando classificadores de texto

Modelos de classificaÃ§Ã£o nÃ£o devem ser avaliados apenas por accuracy.

Existem mÃ©tricas importantes para compreender comportamento do modelo.

---

### Accuracy

Mede a proporÃ§Ã£o de previsÃµes corretas.

---

### Precision

Mede quantas previsÃµes positivas estavam corretas.

---

### Recall

Mede quantos exemplos positivos foram corretamente detectados.

---

### F1-score

Equilibra precision e recall.

---

### Confusion Matrix

Mostra como o modelo erra e acerta cada classe.

![Confusion Matrix](./infograficos/05-metricas-confusion-matrix.svg)

Essa mÃ©trica Ã© fundamental para interpretar modelos em aplicaÃ§Ãµes reais.

---

## InferÃªncia e uso prÃ¡tico do modelo

Depois do treinamento, o modelo pode ser utilizado para classificar novos textos.

Esse processo envolve:

- tokenizar o texto
- executar o modelo
- interpretar probabilidades de classes
- selecionar a classe mais provÃ¡vel

---

## LimitaÃ§Ãµes do Fine-Tuning DidÃ¡tico

Neste projeto utilizamos:

- datasets pequenos
- modelos compactos
- treinamento simplificado

Essas simplificaÃ§Ãµes permitem execuÃ§Ã£o no Colab e facilitam aprendizado conceitual.

---

## O que construiremos no notebook

Neste capÃ­tulo vamos implementar:

- um GPT adaptado para classificaÃ§Ã£o
- reutilizaÃ§Ã£o de pesos prÃ©-treinados
- treinamento supervisionado
- comparaÃ§Ã£o entre estratÃ©gias de fine-tuning
- avaliaÃ§Ã£o com mÃ©tricas de classificaÃ§Ã£o
- inferÃªncia com novos textos

---

## Preparando os prÃ³ximos capÃ­tulos

Depois de aprender fine-tuning supervisionado, surge o prÃ³ximo passo natural:

> Como ensinar modelos a seguir instruÃ§Ãµes humanas?

Nos prÃ³ximos capÃ­tulos exploraremos:

- instruction tuning
- alinhamento de modelos
- RLHF
- tÃ©cnicas modernas de adaptaÃ§Ã£o de LLMs

---

## ðŸ§¾ GlossÃ¡rio RÃ¡pido â€” CapÃ­tulo 06

**Fine-Tuning**  
Processo de adaptar um modelo prÃ©-treinado para uma tarefa especÃ­fica.

**Classification Head**  
Camada adicional usada para prever classes a partir das representaÃ§Ãµes do modelo.

**Freeze**  
Congelar pesos do modelo para evitar atualizaÃ§Ã£o durante treinamento.

**Unfreeze**  
Permitir atualizaÃ§Ã£o dos pesos durante fine-tuning.

**Supervised Dataset**  
Dataset contendo textos e rÃ³tulos associados.

**Confusion Matrix**  
Tabela que mostra acertos e erros de classificaÃ§Ã£o.

---

> Nos capÃ­tulos anteriores ensinamos o modelo a entender linguagem.  
> Neste capÃ­tulo ensinamos o modelo a tomar decisÃµes.

---

### ðŸš€ Execute agora

- **Notebook:** `06-fine-tuning/notebook.ipynb`
- **Abrir direto no Colab:** [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vongrossi/fazendo-um-llm-do-zero/blob/main/06-fine-tuning/notebook.ipynb)
