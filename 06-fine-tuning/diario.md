# Cap√≠tulo 06 ‚Äî Fine-Tuning para Classifica√ß√£o

Nos cap√≠tulos anteriores, aprendemos como construir e treinar um modelo GPT capaz de aprender padr√µes da linguagem.

- transformamos texto em n√∫meros  
- constru√≠mos mecanismos de aten√ß√£o  
- montamos um modelo GPT completo  
- ensinamos o modelo a aprender linguagem  

Agora surge uma nova pergunta:

> Como usamos esse conhecimento para resolver problemas reais?

Este cap√≠tulo responde exatamente isso.

---

## O que √© Fine-Tuning

Um modelo de linguagem aprende padr√µes gerais da linguagem durante o pr√©-treinamento.

Ele aprende:

- gram√°tica
- sem√¢ntica
- rela√ß√µes entre palavras
- estrutura de frases

Mas ele n√£o nasce sabendo executar tarefas espec√≠ficas.

Fine-tuning √© o processo de adaptar um modelo pr√©-treinado para resolver uma tarefa supervisionada.

---

## Pr√©-Treinamento vs Especializa√ß√£o

Podemos imaginar o treinamento de um LLM como o aprendizado humano.

O pr√©-treinamento √© equivalente √† educa√ß√£o b√°sica e geral.

Fine-tuning √© equivalente √† especializa√ß√£o profissional.

![Pr√©-treinamento vs Fine-tuning](./infograficos/01-pretrain-vs-finetune.png)

Durante o pr√©-treinamento o modelo aprende linguagem em geral.  
Durante o fine-tuning o modelo aprende a executar tarefas espec√≠ficas.

---

## Transformando um modelo generativo em classificador

Modelos GPT s√£o projetados para prever o pr√≥ximo token.

Para transformar o modelo em classificador precisamos modificar o objetivo do treinamento.

Em vez de prever a pr√≥xima palavra, o modelo passa a prever uma classe associada ao texto.

---

## Extraindo representa√ß√µes do modelo

Quando um texto passa pelo GPT, cada token gera uma representa√ß√£o contextual.

Essas representa√ß√µes cont√™m o entendimento do modelo sobre o texto.

Para classifica√ß√£o precisamos transformar essas representa√ß√µes em uma decis√£o final.

---

## Classification Head

A solu√ß√£o mais comum √© adicionar uma camada de classifica√ß√£o no topo do modelo.

![Classification Head](./infograficos/02-classification-head.png)

Essa camada recebe a representa√ß√£o do texto e produz logits para cada classe.

Esse processo reutiliza o conhecimento lingu√≠stico j√° aprendido pelo modelo.

---

## Como escolher a representa√ß√£o do texto

Existem diferentes estrat√©gias para extrair uma representa√ß√£o global:

- usar o embedding do √∫ltimo token
- usar m√©dia dos embeddings da sequ√™ncia
- usar tokens especiais

Neste cap√≠tulo utilizaremos uma abordagem simples e did√°tica baseada na √∫ltima posi√ß√£o da sequ√™ncia.

---

## Estrat√©gias de Fine-Tuning

Nem sempre precisamos treinar todo o modelo novamente.

Existem diferentes estrat√©gias:

### Fine-Tuning Completo

Todos os pesos do modelo s√£o atualizados.

Vantagens:
- maior capacidade de adapta√ß√£o

Desvantagens:
- maior custo computacional
- maior risco de overfitting

---

### Congelamento de Camadas

Podemos congelar parte do modelo e treinar apenas algumas camadas.

![Freeze vs Unfreeze](./infograficos/03-freeze-vs-unfreeze.png)

Estrat√©gias comuns incluem:

- treinar apenas a camada de classifica√ß√£o
- treinar apenas as √∫ltimas camadas
- liberar gradualmente o treinamento do modelo

Essa abordagem reduz custo computacional e melhora estabilidade.

---

## Treinamento Supervisionado

Fine-tuning utiliza datasets rotulados.

Cada exemplo cont√©m:

- texto de entrada
- r√≥tulo associado

O treinamento passa a minimizar o erro entre a classe prevista e a classe real.

---

## Pipeline de treinamento para classifica√ß√£o

O fluxo geral do fine-tuning √© semelhante ao treinamento do modelo de linguagem, mas com objetivo diferente.

![Pipeline de treinamento supervisionado](./infograficos/04-treino-classificacao-pipeline.png)

O pipeline inclui:

1. Texto rotulado  
2. Tokeniza√ß√£o  
3. Processamento pelo GPT  
4. Extra√ß√£o de representa√ß√£o do texto  
5. Camada de classifica√ß√£o  
6. C√°lculo da loss supervisionada  
7. Atualiza√ß√£o dos pesos  

---

## Avaliando classificadores de texto

Modelos de classifica√ß√£o n√£o devem ser avaliados apenas por accuracy.

Existem m√©tricas importantes para compreender comportamento do modelo.

---

### Accuracy

Mede a propor√ß√£o de previs√µes corretas.

---

### Precision

Mede quantas previs√µes positivas estavam corretas.

---

### Recall

Mede quantos exemplos positivos foram corretamente detectados.

---

### F1-score

Equilibra precision e recall.

---

### Confusion Matrix

Mostra como o modelo erra e acerta cada classe.

![Confusion Matrix](./infograficos/05-metricas-confusion-matrix.png)

Essa m√©trica √© fundamental para interpretar modelos em aplica√ß√µes reais.

---

## Infer√™ncia e uso pr√°tico do modelo

Depois do treinamento, o modelo pode ser utilizado para classificar novos textos.

Esse processo envolve:

- tokenizar o texto
- executar o modelo
- interpretar probabilidades de classes
- selecionar a classe mais prov√°vel

---

## Limita√ß√µes do Fine-Tuning Did√°tico

Neste projeto utilizamos:

- datasets pequenos
- modelos compactos
- treinamento simplificado

Essas simplifica√ß√µes permitem execu√ß√£o no Colab e facilitam aprendizado conceitual.

---

## O que construiremos no notebook

Neste cap√≠tulo vamos implementar:

- um GPT adaptado para classifica√ß√£o
- reutiliza√ß√£o de pesos pr√©-treinados
- treinamento supervisionado
- compara√ß√£o entre estrat√©gias de fine-tuning
- avalia√ß√£o com m√©tricas de classifica√ß√£o
- infer√™ncia com novos textos

---

## Preparando os pr√≥ximos cap√≠tulos

Depois de aprender fine-tuning supervisionado, surge o pr√≥ximo passo natural:

> Como ensinar modelos a seguir instru√ß√µes humanas?

Nos pr√≥ximos cap√≠tulos exploraremos:

- instruction tuning
- alinhamento de modelos
- RLHF
- t√©cnicas modernas de adapta√ß√£o de LLMs

---

## üßæ Gloss√°rio R√°pido ‚Äî Cap√≠tulo 06

**Fine-Tuning**  
Processo de adaptar um modelo pr√©-treinado para uma tarefa espec√≠fica.

**Classification Head**  
Camada adicional usada para prever classes a partir das representa√ß√µes do modelo.

**Freeze**  
Congelar pesos do modelo para evitar atualiza√ß√£o durante treinamento.

**Unfreeze**  
Permitir atualiza√ß√£o dos pesos durante fine-tuning.

**Supervised Dataset**  
Dataset contendo textos e r√≥tulos associados.

**Confusion Matrix**  
Tabela que mostra acertos e erros de classifica√ß√£o.

---

> Nos cap√≠tulos anteriores ensinamos o modelo a entender linguagem.  
> Neste cap√≠tulo ensinamos o modelo a tomar decis√µes.
