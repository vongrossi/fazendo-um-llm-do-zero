{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Cap√≠tulo 06 ‚Äî Fine-Tuning: A Especializa√ß√£o do Modelo\n",
    "\n",
    "Neste cap√≠tulo, vamos transformar o nosso GPTMini em um especialista em detectar Spam. \n",
    "\n",
    "--- \n",
    "### üéØ O Poder da Adapta√ß√£o\n",
    "O Fine-tuning pega o conhecimento estrutural do Backbone e o canaliza para uma tarefa de classifica√ß√£o bin√°ria.\n",
    "\n",
    "![Pretrain vs Finetune](./infograficos/01-pretrain-vs-finetune.png)"
   ],
   "metadata": { "id": "header" }
  },
  {
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# Setup do reposit√≥rio no Colab\n",
    "# ============================================================\n",
    "import os, sys\n",
    "REPO_NAME = \"fazendo-um-llm-do-zero\"\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    if not os.path.exists(REPO_NAME):\n",
    "        !git clone https://github.com/vongrossi/{REPO_NAME}.git\n",
    "    if os.path.exists(REPO_NAME) and os.getcwd().split('/')[-1] != REPO_NAME:\n",
    "        os.chdir(REPO_NAME)\n",
    "if os.getcwd() not in sys.path: sys.path.append(os.getcwd())\n",
    "print(\"üìÇ Diret√≥rio atual:\", os.getcwd())"
   ],
   "metadata": { "id": "setup-repo" },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os, sys, torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from lib.gptmini import GPTConfig, GPTMini\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"‚úÖ Especialista pronto em: {device}\")\n",
    "\n",
    "# üìÇ Carregamento do Checkpoint do Cap 05\n",
    "if not os.path.exists(\"gpt_checkpoint.pt\"):\n",
    "    from google.colab import files\n",
    "    print(\"üì§ Por favor, suba o 'gpt_checkpoint.pt' gerado no Cap√≠tulo 05:\")\n",
    "    uploaded = files.upload()\n",
    "\n",
    "ckpt = torch.load(\"gpt_checkpoint.pt\", map_location=device)\n",
    "stoi, itos = ckpt['stoi'], ckpt['itos']\n",
    "encode = lambda s: [stoi[c] for c in s if c in stoi]\n",
    "vocab_size = len(stoi)\n",
    "print(f\"üß† Vocabul√°rio de Caracteres Carregado: {vocab_size} tokens.\")"
   ],
   "metadata": { "id": "setup" },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Dataset Supervisionado\n",
    "\n",
    "Usaremos frases curtas rotuladas como Spam (1) ou Normal (0)."
   ],
   "metadata": { "id": "data-header" }
  },
  {
   "cell_type": "code",
   "source": [
    "raw_data = [\n",
    "    (\"ganhe 1 milhao agora clique aqui\", 1),\n",
    "    (\"oferta imperdivel ganhe desconto gratis\", 1),\n",
    "    (\"seu premio esta esperando resgate ja\", 1),\n",
    "    (\"ola tudo bem como voce esta\", 0),\n",
    "    (\"reuniao de equipe amanha as dez\", 0),\n",
    "    (\"voce vai no churrasco no domingo\", 0)\n",
    "]\n",
    "\n",
    "def build_clf_dataset(data, max_len=32):\n",
    "    X, Y = [], []\n",
    "    for text, label in data:\n",
    "        ids = encode(text.lower())\n",
    "        # Padding/Truncate manual para n√≠vel de caractere\n",
    "        ids = ids[:max_len] + [stoi.get(' ', 0)] * (max_len - len(ids))\n",
    "        X.append(ids)\n",
    "        Y.append(label)\n",
    "    return torch.tensor(X).to(device), torch.tensor(Y).to(device)\n",
    "\n",
    "X_train, Y_train = build_clf_dataset(raw_data)\n",
    "print(f\"Exemplos para treino: {len(X_train)}\")"
   ],
   "metadata": { "id": "data-code" },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Classifier Head\n",
    "\n",
    "Plugamos uma camada linear no topo do Backbone para tomar a decis√£o final.\n",
    "\n",
    "![Head](./infograficos/02-classification-head.png)"
   ],
   "metadata": { "id": "model-header" }
  },
  {
   "cell_type": "code",
   "source": [
    "class GPTClassifier(nn.Module):\n",
    "    def __init__(self, backbone, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.clf_head = nn.Linear(backbone.config.d_model, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Extra√≠mos a representa√ß√£o do √∫ltimo caractere (Pooling)\n",
    "        x = self.backbone.emb(x)\n",
    "        x = self.backbone.blocks(x)\n",
    "        x = self.backbone.ln_f(x)\n",
    "        last_token_feat = x[:, -1, :] \n",
    "        return self.clf_head(last_token_feat)\n",
    "\n",
    "backbone = GPTMini(ckpt['config']).to(device)\n",
    "backbone.load_state_dict(ckpt['state_dict'])\n",
    "\n",
    "model = GPTClassifier(backbone).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4)\n",
    "print(\"üèóÔ∏è Modelo especializado constru√≠do.\")"
   ],
   "metadata": { "id": "model-code" },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Treinamento e Avalia√ß√£o\n",
    "\n",
    "Observamos o modelo aprendendo a separar as classes."
   ],
   "metadata": { "id": "train-header" }
  },
  {
   "cell_type": "code",
   "source": [
    "model.train()\n",
    "for step in range(201):\n",
    "    logits = model(X_train)\n",
    "    loss = F.cross_entropy(logits, Y_train)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if step % 50 == 0: print(f\"Step {step:03d} | Loss: {loss.item():.4f}\")\n",
    "\n",
    "def classify(text):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        ids = torch.tensor([encode(text.lower())]).to(device)\n",
    "        # Padding simples\n",
    "        ids = F.pad(ids, (0, 32 - ids.size(1)), value=stoi.get(' ', 0))\n",
    "        pred = torch.argmax(model(ids), dim=-1).item()\n",
    "    return \"üö® SPAM\" if pred == 1 else \"‚úÖ NORMAL\"\n",
    "\n",
    "print(\"\\nüîç TESTE PR√ÅTICO:\")\n",
    "print(f\"'ganhe premio agora': {classify('ganhe premio agora')}\")\n",
    "print(f\"'tudo bem com voce': {classify('tudo bem com voce')}\")"
   ],
   "metadata": { "id": "train-code" },
   "execution_count": null,
   "outputs": []
  }
 ]\n,
 "metadata": {
  "kernelspec": { "display_name": "Python 3", "language": "python", "name": "python3" },
  "language_info": { "name": "python", "version": "3.12.3" }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}